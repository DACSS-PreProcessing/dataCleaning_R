<br> 
<center><img src="https://github.com/DACSS-PreProcessing/Week_1_main/blob/main/pics/LogoSimple.png?raw=true" width="700"></center>



# Data Cleaning in R

```{r klippy, echo=FALSE, include=TRUE}
# remotes::install_github("rlesur/klippy")
klippy::klippy(position = c('top', 'right'))
```

## 1. Collect data tables


### Read a File

I have the data on the **Human Development Index** in a  folder in a GitHub repo, which I downloaded from this [link](https://hdr.undp.org/data-center/documentation-and-downloads) (_Table 1_).

```{r, eval=FALSE}
rm(list = ls())
# Location of data file
linkFile="https://github.com/DACSS-PreProcessing/dataCleaning/raw/main/data/HDI_Table.xlsx"
```

Reading the Excel file:

```{r, eval=F,echo=FALSE,message=FALSE}
# Data
hdiFile=rio::import(linkFile)
```
Take a look:

```{r, eval=FALSE}
head(hdiFile,10)
```

## 2. Cleaning Process


### Fix column names

#### Recover column names

Notice that we do not have the right column names. So we need to save them before we go on:


```{r, eval=FALSE}

RealHeaders=paste(c(hdiFile[5,1:2],hdiFile[4,3:15]))

# these are:
RealHeaders

```

Let's put the rown in the right place:

```{r, eval=FALSE}
# rename all the columns
names(hdiFile)=RealHeaders# R will rename duplicated column names

# newDF
better_1=hdiFile

# see head
head(better_1)
```


#### Subset to drop unneeded columns


Notice the repeated column names (HDI rank) and _NaN_. Notice also that we do not need the last three columns. Let's  rewrite the original:

```{r, eval=FALSE}
# without the last four
better_2=better_1[,1:11]
```

We still have column names with missing values:
```{r, eval=FALSE}
names(better_2)
```
...let's get rid of those columns with the text "NA":
```{r, eval=FALSE}
# save BAD positions 
BadHeaders=grep("NA",names(better_2)) #"NA" is NA
BadHeaders
```
We use the previous result to rewrite the original:
```{r, eval=FALSE}
#subsetting again to keep the good headers
better_2=better_2[,-grep("NA",names(better_2))]
#see
names(better_2)
```

It is time to offer a better set of column names.

#### Clean column names

The current situation:

```{r, eval=FALSE}
better_3=better_2
names(better_3)
```

Notice above that the columns:
* Have acronyms in parenthesis.
* Have spaces between words.

Let's get rid of the acronyms in parentheses:

```{r, eval=FALSE}
# bye anything between parentheses (then TRIM and title case)

library(magrittr)

pattern1='\\(.+\\)'
names(better_3)=gsub(pattern1,replacement = "",names(better_3))%>%
                    trimws()%>%
                        tools::toTitleCase()
names(better_3)
```


**Option 1**: Underscores instead of _blank spaces_.


```{r, eval=FALSE}
# spaces replaced
pattern2='\\s+'
names(better_3)%>%gsub(pattern2,'_',.)
```

**Option 2**: Shorthening using Camel case


```{r, eval=FALSE}
# bye spaces
names(better_3)%>%gsub(pattern2,'',.)
```

**Option 3**: Shorthening using Acronyms

This option requires a good data dictionary in your README. Notice we will do this only for the _variables_:

```{r, eval=FALSE}
acronyms=abbreviate(names(better_3)[-c(1,2)],1,named = F)
acronyms
```
```{r, eval=FALSE}
names(better_3)= c(names(better_3)[1:2], acronyms)
names(better_3)
```

We keep the last alternative:

```{r, eval=FALSE}
head(better_3,10)
```

### Fix Data contents

After becoming familar with the data, we focus on data contents.

#### Cleaning based on cells with missing values:

See all rows with at least one missing value:

```{r, eval=FALSE}
# next DF
better_4=better_3

better_4[!complete.cases(better_4),] 
```

The exploration let us find that we have 84 rows with at least one missing value.

* First decision, drop rows where all variable values are missing:
```{r, eval=FALSE}
# will keep rows where there is at least one value in the variable columns

better_4=better_4 %>% filter(if_any(3:7, ~!is.na(.x)))

# filtered!
better_4
```


* Second decision: drop the rows with where 'Country', the ID, is missing.


```{r, eval=FALSE}
better_4=better_4[complete.cases(better_4$Country),]
better_4
```

* Third decision : Keep rows with some important values:

```{r, eval=FALSE}
# detecting non-numeric cells in HDI
better_4[!complete.cases(as.numeric(better_4$HDI)),]
```


```{r, eval=FALSE}
# then
better_4=better_4[complete.cases(as.numeric(better_4$HDI)),]
better_4
```


Let's explore why some rows have no ranking:

```{r, eval=FALSE}
better_4[!complete.cases(better_4[,c('HDI Rank')]),]
```
```{r, eval=FALSE}
better_4=better_4[complete.cases(better_4[,c('HDI Rank')]),]
better_4
```

#### Preventive Cleaning

It seems pretty clean. However, let's play safe and get rid of trailing or leading spaces :

```{r, eval=FALSE}
# no trailing nor leading spaces
better_4$Country=trimws(better_4$Country,whitespace = "[\\h\\v]")
```

Are the numeric values read as strings?
```{r, eval=FALSE}
better_4[1,]
```

If you do not get a zero, you have dirty numeric values:
```{r, eval=FALSE}
colSums(is.na(apply(better_4[,-c(1,2)],2, as.numeric)))
```

Notice these cases:

```{r, eval=FALSE}
sum(is.na(as.numeric(c('1','34',34))))
```
```{r, eval=FALSE}
sum(is.na(as.numeric(c('1,8','3..4',34))))
```

We did not have a cell with the inappropiate characters representing numerical values, but what if:

```{r, eval=FALSE}
var1=c("1",'$3,4',"5.6","2.3",1)
var2=c("1.3",'3 400',"5'6","211.333",15)
test=as.data.frame(cbind(var1,var2))
test
```

This code may come in handy:

```{r, eval=FALSE}
badValues=c() # empty vector, here we will save the wrong strings
goodStringForNumbers='^\\d+\\.*\\d*$'
for (col in names(test)){
    currentBad=grep(goodStringForNumbers, test[,col], invert = TRUE, value = TRUE)
    badValues=c(badValues,unique(currentBad))
    
}

unique(badValues)
```



We finished the cleaning. Let's reset the row indexes to finish the job:

```{r, eval=FALSE}
rownames(better_4)=NULL
better_4
```

